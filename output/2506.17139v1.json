{
    "paper_id": "2506.17139v1",
    "llm_output": "Below are three self‑contained graduate‑level exercises based exactly on analytic results from the paper “Consistent Sampling and Simulation: Molecular Dynamics with Energy‑Based Diffusion Models.” Each question provides all necessary definitions and assumptions, followed by a clear “Task” and then a “Solution” that quotes the final expression verbatim from the paper.\n\n---\n\n### Problem 1\n\n**Background.**  \nIn the variance‑preserving (VP) diffusion formulation the forward stochastic differential equation (SDE) is defined by  \n\\[\n\\d{\\mathbf{x}} = \\mathbf{f}(\\mathbf{x}, t)\\,\\d{t} + g(t)\\,\\d{\\mathbf{w}},\n\\]  \nwith drift and diffusion coefficients chosen as  \n\\[\n\\mathbf{f}(\\mathbf{x},t) = -\\tfrac{1}{2}\\beta(t)\\,\\mathbf{x}, \\quad g(t)=\\sqrt{\\beta(t)}\\,,\n\\]  \nwhere the noise schedule is given by  \n\\[\n\\beta(t)=\\beta_{\\min}+t\\cdot(\\beta_{\\max}-\\beta_{\\min}).\n\\]  \nUnder these assumptions the forward process is linear in \\(\\mathbf{x}\\) and its solution (i.e. the transition kernel) can be written in closed form as a Gaussian probability density.  \n\n**Task.**  \nDerive the analytic expression for the transition kernel  \n\\[\np_t(\\mathbf{x}(t) \\mid \\mathbf{x}(0))\n\\]  \nin closed form, showing that it is a Gaussian with a mean that is a scaled version of \\(\\mathbf{x}(0)\\) and covariance proportional to the identity matrix.\n\n**Solution.**  \nThe paper states the final transition kernel as follows:  \n\\[\np_t(\\mathbf{x}(t) \\mid \\mathbf{x}(0)) = \\mathcal{N}\\Bigl(\\mathbf{x}(t);\\,e^{-\\frac{1}{2}\\int_{0}^{t}\\beta(s)\\,\\mathrm{d}s}\\,\\mathbf{x}(0),\\,\\bigl(1-e^{-\\int_{0}^{t}\\beta(s)\\,\\mathrm{d}s}\\bigr)I\\Bigr).\n\\]\nSee the paragraph beginning “With this specific choice…” in the paper.\n\n---\n\n### Problem 2\n\n**Background.**  \nSuppose that a molecular system has an equilibrium (Boltzmann) distribution given by  \n\\[\np(\\mathbf{x}) = \\frac{\\exp\\Bigl(-\\frac{U(\\mathbf{x})}{k_BT}\\Bigr)}{Z},\n\\]  \nwhere \\(U(\\mathbf{x})\\) is the potential energy, \\(k_BT\\) is the thermal energy, and \\(Z\\) is a normalization constant. Diffusion models trained on equilibrium (Boltzmann‑distributed) data learn a score function defined as  \n\\[\n\\mathbf{s}(\\mathbf{x},t) \\approx \\nabla_{\\mathbf{x}} \\log p_t(\\mathbf{x}).\n\\]  \nWhen the model is evaluated at the final time \\(t=0\\) (corresponding to data), the score relates directly to the forces.  \n\n**Task.**  \nDerive the final expression that relates the score at \\(t=0\\) to the forces by computing  \n\\[\n\\nabla_{\\mathbf{x}} \\log p_{t=0}(\\mathbf{x}),\n\\]  \nand show that it is proportional to \\(-\\nabla_{\\mathbf{x}} U(\\mathbf{x})\\).\n\n**Solution.**  \nThe paper gives the following relationship:\n\\[\n\\mathbf{s}(\\mathbf{x},t=0) \\approx \\nabla_{\\mathbf{x}} \\log p_{t=0}(\\mathbf{x}) \n= \\nabla_{\\mathbf{x}} \\log\\exp\\Bigl(-\\frac{U(\\mathbf{x})}{k_BT}\\Bigr) - \\nabla_{\\mathbf{x}}\\log Z \n= -\\frac{1}{k_BT}\\nabla_{\\mathbf{x}} U(\\mathbf{x}).\n\\]\nSee the paragraph following Equation (17) in the paper.\n\n---\n\n### Problem 3\n\n**Background.**  \nFor a diffusion model whose unnormalized density \\( \\log p_t(\\mathbf{x}) \\) is parameterized via an energy‐based (conservative) network, the Fokker–Planck equation in log‑density form reads  \n\\[\n\\partial_t \\log p_t(\\mathbf{x}) = \\mathcal{F}_{p}(\\mathbf{x},t) \\triangleq \\frac{1}{2}g^2(t)\\Bigl[\\operatorname{div}_{\\mathbf{x}}\\bigl(\\nabla_{\\mathbf{x}}\\log p_t(\\mathbf{x})\\bigr)+\\left\\Vert\\nabla_{\\mathbf{x}}\\log p_t(\\mathbf{x})\\right\\Vert_2^2\\Bigr] -\\langle \\mathbf{f}(\\mathbf{x},t),\\nabla_{\\mathbf{x}}\\log p_t(\\mathbf{x})\\rangle -\\operatorname{div}_{\\mathbf{x}}(\\mathbf{f}(\\mathbf{x},t)).\n\\]\nDefining the Fokker–Planck residual by  \n\\[\nR(\\mathbf{x},t)=\\mathcal{F}_{p}(\\mathbf{x},t)-\\partial_t \\log p_t(\\mathbf{x}),\n\\]\nthe paper introduces a “weak” residual obtained by averaging over a small Gaussian perturbation \\(\\mathbf{v}\\sim\\mathcal{N}(0,\\sigma^2 I)\\). This helps to obtain an unbiased estimator requiring only first‑order derivatives.  \n\n**Task.**  \nDerive the unbiased estimator of the weak residual using a sample \\(\\mathbf{v}\\) and show that it can be expressed as  \n\\[\n\\begin{aligned}\n\\widetilde{R}(\\mathbf{x},t;\\mathbf{v}) = \\; &\\frac{1}{2}g^2(t)\\left[ \\left(\\frac{\\mathbf{v}}{\\sigma}\\right)^{\\top}\\frac{\\mathbf{s}(\\mathbf{x}+\\mathbf{v},t)-\\mathbf{s}(\\mathbf{x}-\\mathbf{v},t)}{2\\sigma}+\\left\\Vert \\mathbf{s}(\\mathbf{x}+\\mathbf{v},t)\\right\\Vert^2_2\\right] \\\\\n&-\\langle \\mathbf{f}(\\mathbf{x}+\\mathbf{v},t),\\mathbf{s}(\\mathbf{x}+\\mathbf{v},t)\\rangle-\\operatorname{div}_{\\mathbf{x}}(\\mathbf{f}(\\mathbf{x}+\\mathbf{v},t))-\\partial_t \\log p_t(\\mathbf{x}+\\mathbf{v}).\n\\end{aligned}\n\\]\n\n**Solution.**  \nThe paper states the result verbatim in its theorem on the weak residual formulation. The final expression given is:\n\\[\n\\begin{aligned}\n\\widetilde{R}(\\mathbf{x},t;\\mathbf{v}) = \\; &\\frac{1}{2} g^2(t) \\left[ \\left(\\frac{\\mathbf{v}}{\\sigma}\\right)^{\\top}\\frac{\\mathbf{s}(\\mathbf{x}+\\mathbf{v},t)-\\mathbf{s}(\\mathbf{x}-\\mathbf{v},t)}{2\\sigma} + \\left\\Vert\\mathbf{s}(\\mathbf{x}+\\mathbf{v},t)\\right\\Vert^2_2 \\right] \\\\\n&\n - \\langle \\mathbf{f}(\\mathbf{x}+\\mathbf{v},t), \\mathbf{s}(\\mathbf{x}+\\mathbf{v},t) \\rangle - \\operatorname{div}_{\\mathbf{x}}\\bigl(\\mathbf{f}(\\mathbf{x}+\\mathbf{v},t)\\bigr) - \\partial_t \\log p_t(\\mathbf{x}+\\mathbf{v}).\n\\end{aligned}\n\\]\nMoreover, this yields an unbiased estimator of the squared residual via\n\\[\n\\left\\Vert \\widetilde{R}(\\mathbf{x},t)\\right\\Vert_2^2 \\approx \\widetilde{R}(\\mathbf{x},t;\\mathbf{v})\\cdot \\widetilde{R}(\\mathbf{x},t;\\mathbf{v}') \\quad\\text{with}\\quad \\mathbf{v},\\mathbf{v}'\\sim\\mathcal{N}(0,\\sigma^2 I).\n\\]\nSee “Theorem” (labeled in the paper) and the accompanying discussion in the “Finite Difference Approximation” section.\n\n--- \n\nThese problems are designed to test your understanding of the analytic derivations that underpin the energy‑based diffusion modeling approach for consistent molecular sampling and simulation as presented in the paper."
}