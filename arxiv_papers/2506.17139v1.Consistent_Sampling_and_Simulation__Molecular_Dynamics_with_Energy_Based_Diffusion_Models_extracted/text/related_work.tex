\section{Related Work}
In recent years, a variety of deep learning methods have been proposed to enhance or replace molecular simulation. The work most closely related to ours is that of \citet{arts2023}, who employ an energy-based diffusion model for coarse‑grained systems. However, their approach fails to maintain consistency between sampling and simulation. Moreover, they mitigate some of the inconsistencies we describe by evaluating the diffusion model at larger timesteps $\t > 0$, which introduces additional noise and reduces structural fidelity. We compare against this model in \cref{sec:experiments} and show that evaluating at a different $t$ is not a suitable way to prevent this mismatch. Several works instead learn coarse‑grained force fields via a force‑matching objective \citep{husic2020coarse,kohler2023flow,charron2023navigating,durumeric2024learning}. Rather than training a model to represent the data distribution directly, these methods aim to approximate the target forces. However, these models typically require system-specific energy priors, which rely heavily on domain knowledge. 

Other approaches bypass MD sampling entirely, generating Boltzmann distributed configurations either sequentially, by conditioning each sample on its predecessor \citep{dibak2021temperature, plainer2023transition, schreiner2023implicit, tamagnone2024coarse}, or completely independently \citep{noe2019boltzmann, wirnsberger2020targeted, kohler2020equivariant, midgley2022flow, klein2023equivariant,abdin2023pepflow, kim2024scalableNormFlows, wu2024reaction, schebek2024efficient, diez2024generation, tan2025scalable}. These methods frequently leverage diffusion- or flow-based architectures. In the latter case, for all-atom systems with known energy functions, they can guarantee asymptotically unbiased sampling via reweighting or integration into an MCMC scheme. Although this is often a desirable property, extending it to larger systems remains challenging, as \gls{CG} is not possible.

The inaccurate behavior of the score function has also been studied in low-dimensional settings by \cite{koehler2023statistical, li2023generalization}, who demonstrated inconsistencies and derived error bounds. \cite{lai2023} also proposed a Fokker-Planck-inspired regularization; however, unlike our approach, their method applies a higher-order regularization to the score itself to improve iid sample quality, rather than enforcing consistency through the potential. Relatedly, \citet{hu2024scorebased} propose a score-based solver for high-dimensional Fokker-Planck equations, focusing on solving general SDE forward problems, and \citep{du2024doob} use the Fokker-Planck equation to describe \gls{MD} as a series of Gaussians that can be integrated but do not use any training data, limiting the expressiveness. 
